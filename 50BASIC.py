import json
import torch
import pandas as pd
import re
from transformers import AutoTokenizer, AutoModelForCausalLM

# ğŸ”¹ Parquet íŒŒì¼ ë¡œë“œ
df = pd.read_parquet("eLife_reordered.parquet")
print(f"ì´ article ê°œìˆ˜: {len(df)}")
def extract_clean_summary(full_output):
    """'Now, write the summary:' ì´í›„ ~ 'summary end' ë˜ëŠ” ì¤„ë°”ê¿ˆ ì „ê¹Œì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    start_match = re.search(r"Now, write the summary:\s*", full_output)
    if not start_match:
        return ""
    start_idx = start_match.end()
    end_match = re.search(r"summary end", full_output[start_idx:], re.IGNORECASE)
    end_idx = start_idx + end_match.start() if end_match else None
    summary_body = full_output[start_idx:end_idx].strip()
    return summary_body

# ğŸ”¹ ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
results = []

# ğŸ” 1~5ë²ˆ article ë°˜ë³µ ì²˜ë¦¬
for idx in range(50):
    article = df.loc[idx, "article"]

    # ëª¨ë¸ ë¡œë“œ (ë§¤ë²ˆ ìƒˆë¡œ)
    model_path = "/data/a5252545/model"
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.bfloat16,
        device_map="auto"
    )
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
        "You are a biomedical writing assistant. Generate a high-quality lay summary of the given biomedical research article. "
        "Your summary should be understandable to non-expert readers.\n"
        ### Article:{article}
        Now, write the summary:
        """.strip()


    # ëª¨ë¸ ì‹¤í–‰
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=8192).to("cuda")

    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_new_tokens=1200,
            eos_token_id=tokenizer.eos_token_id,
            repetition_penalty=1.2,
        )

    full_output = tokenizer.decode(output[0], skip_special_tokens=True)
    cleaned_summary = extract_clean_summary(full_output)

    results.append({
        "index": idx,
        "summary": cleaned_summary
    })

    print(f"[{idx+1}/50] ìš”ì•½ ì™„ë£Œ")

    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del model
    del tokenizer
    torch.cuda.empty_cache()

# ğŸ”¹ CSV ì €ì¥
summary_df = pd.DataFrame(results)
summary_df.to_csv("50BasicSummary.csv", index=False, encoding="utf-8")
print("âœ… ëª¨ë“  ìš”ì•½ ì™„ë£Œ ë° ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
